{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Reshape, Flatten, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fer2013.csv')\n",
    "\n",
    "labels = df[df.columns[0]]\n",
    "#changing output labels to categorical format\n",
    "labels = np_utils.to_categorical(labels)\n",
    "image_pixels_string = df[df.columns[1]]\n",
    "image = np.zeros((df.shape[0], 48*48))\n",
    "\n",
    "#forming image matrix of size 1, 48*48\n",
    "for ix in range(image.shape[0]):\n",
    "    temp = image_pixels_string[ix].split(' ')\n",
    "    for iy in range(image.shape[1]):\n",
    "        image[ix, iy] = int(temp[iy])\n",
    "\n",
    "#usig sklearn to normalize each feature\n",
    "image = scale(image, axis=0)\n",
    "\n",
    "#forming training dataset and reshaping it to format accepted by input layer\n",
    "X_train_num = (df[df['Usage']=='Training']).count()[0]\n",
    "X_train = image[:X_train_num, :].reshape((X_train_num, 48, 48, 1))\n",
    "y_train = labels[:X_train_num, :]\n",
    "\n",
    "#forming tcross validation dataset and reshaping it to format accepted by input layer\n",
    "X_cv_num = (df[df['Usage']=='PublicTest']).count()[0]\n",
    "X_cv = image[:X_cv_num, :].reshape((X_cv_num, 48, 48, 1))\n",
    "y_cv = labels[:X_cv_num, :]\n",
    "\n",
    "#forming ttesting dataset and reshaping it to format accepted by input layer\n",
    "X_test_num = (df[df['Usage']=='PrivateTest']).count()[0]\n",
    "X_test = image[:X_test_num, :].reshape((X_test_num, 48, 48, 1))\n",
    "y_test = labels[:X_test_num, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 320,999\n",
      "Trainable params: 320,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(48, 48, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/4\n",
      "28709/28709 [==============================] - 574s 20ms/step - loss: 1.7552 - acc: 0.2843 - val_loss: 1.5586 - val_acc: 0.3848\n",
      "Epoch 2/4\n",
      "28709/28709 [==============================] - 631s 22ms/step - loss: 1.5468 - acc: 0.4007 - val_loss: 1.4123 - val_acc: 0.4553\n",
      "Epoch 3/4\n",
      "28709/28709 [==============================] - 655s 23ms/step - loss: 1.4297 - acc: 0.4542 - val_loss: 1.3281 - val_acc: 0.4999\n",
      "Epoch 4/4\n",
      "28709/28709 [==============================] - 684s 24ms/step - loss: 1.3458 - acc: 0.4880 - val_loss: 1.2254 - val_acc: 0.5339\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5641b3c96617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      validation_data=(X_cv, y_cv))\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_model' is not defined"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                     epochs=4,\n",
    "                     shuffle=True,\n",
    "                      batch_size=256,\n",
    "                     validation_data=(X_cv, y_cv))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('live_emotion_recognition_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "fhandle = h5py.File('live_emotion_recognition_model.h5', 'r+')\n",
    "del fhandle['optimizer_weights']\n",
    "fhandle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
