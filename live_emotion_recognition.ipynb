{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Reshape, Flatten, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('fer2013.csv')\n",
    "\n",
    "df_labels = pd.read_csv('fer2013new.csv')\n",
    "#changing output labels to categorical format\n",
    "image_pixels_string = df_data[df_data.columns[1]]\n",
    "image = np.zeros((df_data.shape[0], 48*48))\n",
    "\n",
    "#forming image matrix of size 1, 48*48\n",
    "for ix in range(image.shape[0]):\n",
    "    temp = image_pixels_string[ix].split(' ')\n",
    "    for iy in range(image.shape[1]):\n",
    "        image[ix, iy] = int(temp[iy])\n",
    "\n",
    "#usig sklearn to normalize each feature\n",
    "image = scale(image, axis=0)\n",
    "\n",
    "#forming training dataset and reshaping it to format accepted by input layer\n",
    "X_train_num = (df_data[df_data['Usage']=='Training']).count()[0]\n",
    "X_train = image[:X_train_num, :].reshape((X_train_num, 48, 48, 1))\n",
    "y_train = df_labels[df_labels['Usage']=='Training'].iloc[:,2:]/10\n",
    "\n",
    "#forming tcross validation dataset and reshaping it to format accepted by input layer\n",
    "X_cv_num = (df_data[df_data['Usage']=='PublicTest']).count()[0]\n",
    "X_cv = image[X_train_num:X_train_num+X_cv_num, :].reshape((X_cv_num, 48, 48, 1))\n",
    "y_cv = df_labels[df_labels['Usage']=='PublicTest'].iloc[:,2:]/10\n",
    "\n",
    "#forming ttesting dataset and reshaping it to format accepted by input layer\n",
    "X_test_num = (df_data[df_data['Usage']=='PrivateTest']).count()[0]\n",
    "X_test = image[X_train_num+X_cv_num:,:].reshape((X_test_num, 48, 48, 1))\n",
    "y_test = df_labels[df_labels['Usage']=='PrivateTest'].iloc[:,2:]/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 620,714\n",
      "Trainable params: 620,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(48, 48, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/5\n",
      "28709/28709 [==============================] - 503s 18ms/step - loss: 1.8704 - acc: 0.3501 - val_loss: 1.7258 - val_acc: 0.4132\n",
      "Epoch 2/5\n",
      "28709/28709 [==============================] - 501s 17ms/step - loss: 1.5852 - acc: 0.5450 - val_loss: 1.4288 - val_acc: 0.6166\n",
      "Epoch 3/5\n",
      "28709/28709 [==============================] - 489s 17ms/step - loss: 1.3986 - acc: 0.6335 - val_loss: 1.2922 - val_acc: 0.6626\n",
      "Epoch 4/5\n",
      "28709/28709 [==============================] - 492s 17ms/step - loss: 1.3173 - acc: 0.6710 - val_loss: 1.2162 - val_acc: 0.6877\n",
      "Epoch 5/5\n",
      "28709/28709 [==============================] - 492s 17ms/step - loss: 1.2489 - acc: 0.6991 - val_loss: 1.1778 - val_acc: 0.7152\n",
      "*****************************************\n",
      "* Testing loss : 1.2342256356428247  *\n",
      "* Testing accuracy : 0.6968514906700756 *\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                     epochs=5,\n",
    "                     shuffle=True,\n",
    "                      batch_size=256,\n",
    "                     validation_data=(X_cv, y_cv))\n",
    "\n",
    "print('*****************************************')\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('* Testing loss : {}  *'.format(score[0]))\n",
    "print('* Testing accuracy : {} *'.format(score[1]))\n",
    "print('*****************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('live_emotion_recognition_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "fhandle = h5py.File('live_emotion_recognition_model.h5', 'r+')\n",
    "del fhandle['optimizer_weights']\n",
    "fhandle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
